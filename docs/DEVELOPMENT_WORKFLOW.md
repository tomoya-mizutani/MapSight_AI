# MapSight_AI é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

## æ¦‚è¦

MapSight_AIãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€VSCodeã§ã®é–‹ç™ºã¨Google Colabã§ã®ãƒ†ã‚¹ãƒˆãƒ»é‹ç”¨ã‚’çµ„ã¿åˆã‚ã›ãŸãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰é–‹ç™ºãƒ•ãƒ­ãƒ¼ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€åŠ¹ç‡çš„ãªé–‹ç™ºæ‰‹é †ã¨æ³¨æ„ç‚¹ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚

## ğŸ”„ é–‹ç™ºãƒ•ãƒ­ãƒ¼æ¦‚è¦

```mermaid
flowchart TD
    A[VSCodeé–‹ç™º] --> B[ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ]
    B --> C[Gitç®¡ç†]
    C --> D[ColabåŒæœŸ]
    D --> E[Colabæ¤œè¨¼]
    E --> F[æœ¬ç•ªé‹ç”¨]
    F --> G[ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯]
    G --> A
```

### åŸºæœ¬çš„ãªå½¹å‰²åˆ†æ‹…

| ç’°å¢ƒ | ç”¨é€” | åˆ©ç‚¹ |
|------|------|------|
| **VSCode** | ã‚³ãƒ¼ãƒ‰é–‹ç™ºãƒ»ãƒ‡ãƒãƒƒã‚° | ã‚¨ãƒ‡ã‚£ã‚¿æ©Ÿèƒ½ã€æ‹¡å¼µæ©Ÿèƒ½ã€Gitçµ±åˆ |
| **Google Colab** | ãƒ†ã‚¹ãƒˆãƒ»é‹ç”¨ãƒ»å®Ÿé¨“ | GPUåˆ©ç”¨ã€ç’°å¢ƒçµ±ä¸€ã€å…±æœ‰ã—ã‚„ã™ã• |

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
MapSight_AI/
â”œâ”€â”€ src/                        # é–‹ç™ºã‚³ãƒ¼ãƒ‰ï¼ˆVSCodeï¼‰
â”‚   â”œâ”€â”€ segment_rounds.py
â”‚   â”œâ”€â”€ crop_minimap.py
â”‚   â”œâ”€â”€ clean_same_frames.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ notebooks/                  # Colabãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
â”‚   â”œâ”€â”€ dev_test.ipynb          # é–‹ç™ºç”¨ãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ production.ipynb        # æœ¬ç•ªç”¨
â”‚   â””â”€â”€ experiments/            # å®Ÿé¨“ç”¨
â”œâ”€â”€ tests/                      # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ test_segment.py
â”‚   â”œâ”€â”€ test_crop.py
â”‚   â””â”€â”€ test_data/
â”œâ”€â”€ docs/                       # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”‚   â”œâ”€â”€ DEVELOPMENT_WORKFLOW.md
â”‚   â””â”€â”€ API_REFERENCE.md
â”œâ”€â”€ config/                     # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ dev_config.yaml
â”‚   â”œâ”€â”€ colab_config.yaml
â”‚   â””â”€â”€ production_config.yaml
â”œâ”€â”€ requirements/               # ä¾å­˜é–¢ä¿‚
â”‚   â”œâ”€â”€ requirements_dev.txt
â”‚   â”œâ”€â”€ requirements_colab.txt
â”‚   â””â”€â”€ requirements_base.txt
â””â”€â”€ utils/                      # å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    â”œâ”€â”€ path_manager.py
    â”œâ”€â”€ env_checker.py
    â””â”€â”€ data_sync.py
```

## ğŸ› ï¸ é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### VSCodeé–‹ç™ºç’°å¢ƒ

#### 1. å¿…è¦ãªæ‹¡å¼µæ©Ÿèƒ½

```json
// .vscode/extensions.json
{
    "recommendations": [
        "ms-python.python",
        "ms-python.black-formatter",
        "ms-python.flake8",
        "ms-toolsai.jupyter",
        "ms-vscode.test-adapter-converter",
        "github.copilot"
    ]
}
```

#### 2. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

```json
// .vscode/settings.json
{
    "python.defaultInterpreterPath": "./venv/bin/python",
    "python.testing.pytestEnabled": true,
    "python.testing.pytestArgs": ["tests"],
    "python.formatting.provider": "black",
    "python.linting.flake8Enabled": true,
    "files.exclude": {
        "**/__pycache__": true,
        "**/.*": false
    }
}
```

#### 3. ä»®æƒ³ç’°å¢ƒè¨­å®š

```bash
# ä»®æƒ³ç’°å¢ƒä½œæˆ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements/requirements_dev.txt
```

### ç’°å¢ƒäº’æ›æ€§ç®¡ç†

#### ãƒ‘ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

```python
# utils/path_manager.py
import os
from pathlib import Path

class PathManager:
    """VSCodeã¨Colabç’°å¢ƒã®ãƒ‘ã‚¹ç®¡ç†"""
    
    def __init__(self):
        self.is_colab = self._detect_colab()
        self.setup_environment()
    
    def _detect_colab(self):
        """Colabç’°å¢ƒã®æ¤œå‡º"""
        try:
            import google.colab
            return True
        except ImportError:
            return False
    
    def setup_environment(self):
        """ç’°å¢ƒã«å¿œã˜ãŸãƒ‘ã‚¹è¨­å®š"""
        if self.is_colab:
            self.base_path = Path("/content/drive/MyDrive/MapSight_AI")
            self._ensure_colab_setup()
        else:
            # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒï¼ˆVSCodeï¼‰
            self.base_path = Path(__file__).parent.parent
    
    def _ensure_colab_setup(self):
        """Colabç’°å¢ƒã®åˆæœŸè¨­å®šç¢ºèª"""
        if not self.base_path.exists():
            raise RuntimeError(
                "Google Drive not mounted or MapSight_AI not found. "
                "Please run: drive.mount('/content/drive')"
            )
    
    def get_path(self, relative_path: str) -> Path:
        """ç’°å¢ƒã«å¿œã˜ãŸçµ¶å¯¾ãƒ‘ã‚¹ã‚’è¿”ã™"""
        return self.base_path / relative_path
    
    def frames_dir(self, date: str) -> Path:
        """ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹"""
        return self.get_path(f"data/frames/{date}")
    
    def template_path(self, template_name: str = "Match_End_template.jpg") -> Path:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"""
        return self.get_path(f"data/templates/{template_name}")
    
    def output_dir(self, date: str) -> Path:
        """å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹"""
        return self.get_path(f"data/{date}")
    
    def config_path(self, config_name: str = "config.yaml") -> Path:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹"""
        if self.is_colab:
            return self.get_path(f"config/colab_{config_name}")
        else:
            return self.get_path(f"config/dev_{config_name}")

# ä½¿ç”¨ä¾‹
pm = PathManager()
frames = pm.frames_dir("2025-06-10")
template = pm.template_path()
config = pm.config_path()
```

#### ç’°å¢ƒä¾å­˜é–¢ä¿‚ç®¡ç†

```python
# utils/env_checker.py
import sys
import subprocess
import importlib
from typing import Dict, List, Tuple

class EnvironmentChecker:
    """ç’°å¢ƒä¾å­˜é–¢ä¿‚ã®ç¢ºèªã¨ç®¡ç†"""
    
    def __init__(self):
        self.is_colab = 'google.colab' in sys.modules
        self.required_packages = self._load_requirements()
    
    def _load_requirements(self) -> Dict[str, str]:
        """ç’°å¢ƒã«å¿œã˜ãŸè¦æ±‚ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®èª­ã¿è¾¼ã¿"""
        if self.is_colab:
            req_file = "requirements/requirements_colab.txt"
        else:
            req_file = "requirements/requirements_dev.txt"
        
        requirements = {}
        try:
            with open(req_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        if '==' in line:
                            package, version = line.split('==')
                            requirements[package] = version
                        else:
                            requirements[line] = None
        except FileNotFoundError:
            print(f"Warning: {req_file} not found")
        
        return requirements
    
    def check_environment(self) -> Tuple[List[str], List[str]]:
        """ç’°å¢ƒãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        missing_packages = []
        version_mismatches = []
        
        for package, required_version in self.required_packages.items():
            try:
                imported_module = importlib.import_module(package)
                if required_version:
                    installed_version = getattr(imported_module, '__version__', None)
                    if installed_version != required_version:
                        version_mismatches.append(
                            f"{package}: required {required_version}, "
                            f"installed {installed_version}"
                        )
            except ImportError:
                missing_packages.append(package)
        
        return missing_packages, version_mismatches
    
    def install_missing_packages(self, packages: List[str]):
        """ä¸è¶³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
        if not packages:
            return
        
        if self.is_colab:
            for package in packages:
                version = self.required_packages.get(package)
                if version:
                    install_cmd = f"pip install {package}=={version}"
                else:
                    install_cmd = f"pip install {package}"
                
                print(f"Installing: {install_cmd}")
                subprocess.run(install_cmd.split(), check=True)
        else:
            print("Please install missing packages manually:")
            for package in packages:
                version = self.required_packages.get(package)
                if version:
                    print(f"  pip install {package}=={version}")
                else:
                    print(f"  pip install {package}")
    
    def setup_colab_environment(self):
        """Colabç’°å¢ƒã®åˆæœŸè¨­å®š"""
        if not self.is_colab:
            return
        
        # Google Drive ãƒã‚¦ãƒ³ãƒˆ
        try:
            from google.colab import drive
            drive.mount('/content/drive')
            print("âœ“ Google Drive mounted")
        except Exception as e:
            print(f"âœ— Failed to mount Google Drive: {e}")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒ™ãƒ«ã®ä¾å­˜é–¢ä¿‚
        system_packages = ['ffmpeg']
        for package in system_packages:
            try:
                subprocess.run(['apt-get', 'install', '-y', package], 
                             check=True, capture_output=True)
                print(f"âœ“ {package} installed")
            except subprocess.CalledProcessError as e:
                print(f"âœ— Failed to install {package}: {e}")
        
        # Python ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒã‚§ãƒƒã‚¯
        missing, mismatches = self.check_environment()
        if missing:
            print(f"Installing missing packages: {missing}")
            self.install_missing_packages(missing)
        
        if mismatches:
            print("Version mismatches detected:")
            for mismatch in mismatches:
                print(f"  {mismatch}")

# ä½¿ç”¨ä¾‹
checker = EnvironmentChecker()
if checker.is_colab:
    checker.setup_colab_environment()
else:
    missing, mismatches = checker.check_environment()
    if missing or mismatches:
        print("Environment issues detected. Please resolve them.")
```

## ğŸ”§ é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### Daily Development Flow

#### 1. æœã®æº–å‚™ï¼ˆVSCodeï¼‰

```bash
# 1. æœ€æ–°ã‚³ãƒ¼ãƒ‰ã®å–å¾—
git pull origin main

# 2. ä»®æƒ³ç’°å¢ƒã®æœ‰åŠ¹åŒ–
source venv/bin/activate

# 3. ä¾å­˜é–¢ä¿‚ã®ç¢ºèª
python utils/env_checker.py

# 4. ãƒ–ãƒ©ãƒ³ãƒä½œæˆï¼ˆæ–°æ©Ÿèƒ½ã®å ´åˆï¼‰
git checkout -b feature/new-functionality
```

#### 2. é–‹ç™ºä½œæ¥­ï¼ˆVSCodeï¼‰

```python
# é–‹ç™ºæ™‚ã®åŸºæœ¬ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
from utils.path_manager import PathManager
from utils.env_checker import EnvironmentChecker

def main():
    # ç’°å¢ƒåˆæœŸåŒ–
    pm = PathManager()
    checker = EnvironmentChecker()
    
    # æ©Ÿèƒ½å®Ÿè£…
    # ...existing code...
    
    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ
    test_result = run_local_tests()
    if not test_result:
        print("Tests failed. Please fix before committing.")
        return False
    
    return True

if __name__ == "__main__":
    main()
```

#### 3. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆï¼ˆVSCodeï¼‰

```python
# tests/test_integration.py
import unittest
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from utils.path_manager import PathManager
from segment_rounds_updated import *

class TestIntegration(unittest.TestCase):
    def setUp(self):
        self.pm = PathManager()
        # å°è¦æ¨¡ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        self.test_frames = self.pm.get_path("tests/test_data/frames")
        self.test_template = self.pm.get_path("tests/test_data/template.jpg")
    
    def test_path_compatibility(self):
        """ãƒ‘ã‚¹ç®¡ç†ã®äº’æ›æ€§ãƒ†ã‚¹ãƒˆ"""
        frames_path = self.pm.frames_dir("2025-06-10")
        self.assertTrue(isinstance(frames_path, Path))
    
    def test_ahash_calculation(self):
        """aHashè¨ˆç®—ã®ãƒ†ã‚¹ãƒˆ"""
        if self.test_frames.exists():
            frame_files = list(self.test_frames.glob("*.jpg"))
            if frame_files:
                hash_val = ahash(frame_files[0])
                self.assertIsInstance(hash_val, int)
                self.assertGreater(hash_val, 0)
    
    def test_colab_simulation(self):
        """Colabç’°å¢ƒã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        # Colabãƒ‘ã‚¹ã®æ¨¡æ“¬
        colab_base = "/tmp/test_colab"
        os.makedirs(colab_base, exist_ok=True)
        
        # ãƒ‘ã‚¹å¤‰æ›ãƒ†ã‚¹ãƒˆ
        local_path = str(self.pm.base_path / "data")
        expected_colab = colab_base + "/data"
        # ãƒ†ã‚¹ãƒˆå®Ÿè£…
        
    def test_small_dataset_processing(self):
        """å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        if self.test_frames.exists() and self.test_template.exists():
            # å®Ÿéš›ã®å‡¦ç†ã‚’å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œ
            result = process_small_dataset(
                self.test_frames, 
                self.test_template,
                dry_run=True
            )
            self.assertIsNotNone(result)

def run_local_tests():
    """ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    loader = unittest.TestLoader()
    suite = loader.discover('tests', pattern='test_*.py')
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    return result.wasSuccessful()

if __name__ == '__main__':
    unittest.main()
```

#### 4. Gitç®¡ç†ï¼ˆVSCodeï¼‰

```bash
# ã‚³ãƒŸãƒƒãƒˆå‰ã®ãƒã‚§ãƒƒã‚¯
# 1. ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿å®Ÿè¡Œ
black src/ tests/

# 2. ãƒªãƒ³ã‚¿ãƒ¼å®Ÿè¡Œ
flake8 src/ tests/

# 3. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
python -m pytest tests/ -v

# 4. ã‚³ãƒŸãƒƒãƒˆ
git add .
git commit -m "feat: add new functionality for round detection

- Implement enhanced template matching
- Add path compatibility for Colab
- Update tests for new features

Closes #123"

# 5. ãƒ—ãƒƒã‚·ãƒ¥
git push origin feature/new-functionality
```

### Colab Integration Flow

#### 1. é–‹ç™ºç”¨ãƒ†ã‚¹ãƒˆãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯

```python
# notebooks/dev_test.ipynb

# Cell 1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŒæœŸ
if not os.path.exists('/content/MapSight_AI'):
    !git clone https://github.com/your-repo/MapSight_AI.git /content/MapSight_AI

%cd /content/MapSight_AI

# ç’°å¢ƒãƒã‚§ãƒƒã‚¯ã¨åˆæœŸåŒ–
from utils.env_checker import EnvironmentChecker
from utils.path_manager import PathManager

checker = EnvironmentChecker()
checker.setup_colab_environment()

pm = PathManager()
print(f"Project base: {pm.base_path}")

# Cell 2: æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
# æœ€æ–°ã‚³ãƒ¼ãƒ‰ã®ãƒ†ã‚¹ãƒˆ
from src.segment_rounds_updated import *

# å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ
test_frames_dir = "/content/drive/MyDrive/MapSight_AI/data/frames/test_small"
test_template = "/content/drive/MyDrive/MapSight_AI/data/templates/Match_End_template.jpg"

if os.path.exists(test_frames_dir) and os.path.exists(test_template):
    print("Running small-scale test...")
    result = segment_rounds_colab(
        test_frames_dir,
        test_template,
        segments=3,
        dry_run=True
    )
    print(f"Test result: {result}")
else:
    print("Test data not found. Please upload test data.")

# Cell 3: æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
import time
import psutil

def benchmark_processing():
    """å‡¦ç†æ€§èƒ½ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    start_time = time.time()
    start_memory = psutil.virtual_memory().used
    
    # å®Ÿéš›ã®å‡¦ç†
    # result = your_processing_function()
    
    end_time = time.time()
    end_memory = psutil.virtual_memory().used
    
    processing_time = end_time - start_time
    memory_used = (end_memory - start_memory) / 1024 / 1024  # MB
    
    print(f"Processing time: {processing_time:.2f}s")
    print(f"Memory used: {memory_used:.2f}MB")
    
    return processing_time, memory_used

# GPUåˆ©ç”¨çŠ¶æ³ç¢ºèª
import torch
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    
    # GPUä½¿ç”¨é‡ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
    torch.cuda.empty_cache()
    memory_before = torch.cuda.memory_allocated()
    
    # å‡¦ç†å®Ÿè¡Œ
    benchmark_processing()
    
    memory_after = torch.cuda.memory_allocated()
    gpu_memory_used = (memory_after - memory_before) / 1024 / 1024  # MB
    print(f"GPU Memory used: {gpu_memory_used:.2f}MB")

# Cell 4: ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
def test_error_scenarios():
    """ã‚¨ãƒ©ãƒ¼ã‚·ãƒŠãƒªã‚ªã®ãƒ†ã‚¹ãƒˆ"""
    scenarios = [
        ("Invalid template path", "/invalid/path/template.jpg"),
        ("Empty frames directory", "/content/empty_dir"),
        ("Corrupted image file", "/content/corrupted.jpg"),
    ]
    
    for scenario_name, test_input in scenarios:
        try:
            print(f"\nTesting: {scenario_name}")
            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            # result = your_function(test_input)
            print("âœ“ Handled gracefully")
        except Exception as e:
            print(f"âœ— Error: {e}")

test_error_scenarios()
```

#### 2. æœ¬ç•ªé‹ç”¨ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯

```python
# notebooks/production.ipynb

# Cell 1: æœ¬ç•ªç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
from google.colab import drive
import os
import time
import signal
import threading

# Google Drive ãƒã‚¦ãƒ³ãƒˆ
drive.mount('/content/drive')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæœ€æ–°ç‰ˆã®å–å¾—
%cd /content
!rm -rf MapSight_AI  # æ—¢å­˜å‰Šé™¤
!git clone https://github.com/your-repo/MapSight_AI.git
%cd MapSight_AI

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶­æŒæ©Ÿèƒ½
def keep_session_alive():
    """Colabã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶­æŒ"""
    while True:
        time.sleep(300)  # 5åˆ†é–“éš”
        print(".", end="", flush=True)

# ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶­æŒ
keep_alive_thread = threading.Thread(target=keep_session_alive, daemon=True)
keep_alive_thread.start()

# Cell 2: æœ¬ç•ªå‡¦ç†å®Ÿè¡Œ
from utils.path_manager import PathManager
from utils.env_checker import EnvironmentChecker
from src.segment_rounds_updated import *

# ç’°å¢ƒåˆæœŸåŒ–
checker = EnvironmentChecker()
checker.setup_colab_environment()

pm = PathManager()

# è¨­å®šèª­ã¿è¾¼ã¿
config_path = pm.config_path("production_config.yaml")
with open(config_path, 'r') as f:
    config = yaml.safe_load(f)

print("=== MapSight_AI Production Run ===")
print(f"Config: {config}")

# Cell 3: ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Ÿè¡Œ
def run_production_pipeline(video_date: str, config: dict):
    """æœ¬ç•ªå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    
    # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆæ©Ÿèƒ½
    checkpoint_file = pm.get_path(f"data/checkpoints/{video_date}_checkpoint.pkl")
    
    try:
        # 1. ãƒ•ãƒ¬ãƒ¼ãƒ ç¢ºèª
        frames_dir = pm.frames_dir(video_date)
        if not frames_dir.exists():
            raise FileNotFoundError(f"Frames directory not found: {frames_dir}")
        
        frames = list(frames_dir.glob("*.jpg"))
        print(f"Found {len(frames)} frames")
        
        # 2. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç¢ºèª
        template_path = pm.template_path()
        if not template_path.exists():
            raise FileNotFoundError(f"Template not found: {template_path}")
        
        # 3. å‡¦ç†å®Ÿè¡Œ
        print("Starting round segmentation...")
        start_time = time.time()
        
        boundaries = segment_rounds_colab(
            str(frames_dir),
            str(template_path),
            segments=config.get('segments', 5),
            end_th=config.get('threshold', 0.5),
            step=config.get('step', 1),
            dry_run=False
        )
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # 4. çµæœä¿å­˜
        result = {
            'video_date': video_date,
            'boundaries': boundaries,
            'processing_time': processing_time,
            'config': config,
            'timestamp': time.time()
        }
        
        result_file = pm.get_path(f"data/results/{video_date}_result.json")
        result_file.parent.mkdir(exist_ok=True)
        
        with open(result_file, 'w') as f:
            json.dump(result, f, indent=2)
        
        print(f"âœ“ Processing completed in {processing_time:.2f}s")
        print(f"âœ“ Results saved to {result_file}")
        
        return result
        
    except Exception as e:
        print(f"âœ— Error occurred: {e}")
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±ä¿å­˜
        error_file = pm.get_path(f"data/errors/{video_date}_error.log")
        error_file.parent.mkdir(exist_ok=True)
        
        with open(error_file, 'w') as f:
            f.write(f"Error: {e}\n")
            f.write(f"Time: {time.time()}\n")
            f.write(f"Config: {config}\n")
        
        raise

# å®Ÿè¡Œ
video_date = "2025-06-10"  # å‡¦ç†å¯¾è±¡æ—¥ä»˜
result = run_production_pipeline(video_date, config)

# Cell 4: çµæœç¢ºèªã¨å¯è¦–åŒ–
import matplotlib.pyplot as plt

def visualize_results(result):
    """çµæœã®å¯è¦–åŒ–"""
    boundaries = result['boundaries']
    video_date = result['video_date']
    
    # å¢ƒç•Œã®å¯è¦–åŒ–
    plt.figure(figsize=(12, 6))
    plt.scatter(boundaries, [1]*len(boundaries), s=100, c='red', marker='|')
    plt.title(f"Round Boundaries - {video_date}")
    plt.xlabel("Frame Index")
    plt.ylabel("Detected Boundaries")
    plt.grid(True)
    plt.show()
    
    # çµ±è¨ˆæƒ…å ±
    segments_length = []
    prev = 0
    for boundary in boundaries + [result.get('total_frames', max(boundaries)+100)]:
        segments_length.append(boundary - prev)
        prev = boundary
    
    plt.figure(figsize=(10, 6))
    plt.bar(range(len(segments_length)), segments_length)
    plt.title(f"Segment Lengths - {video_date}")
    plt.xlabel("Round Number")
    plt.ylabel("Number of Frames")
    plt.grid(True)
    plt.show()
    
    print(f"Average segment length: {sum(segments_length)/len(segments_length):.1f} frames")
    print(f"Total processing time: {result['processing_time']:.2f} seconds")

if 'result' in locals():
    visualize_results(result)
```

## âš ï¸ é‡è¦ãªæ³¨æ„ç‚¹

### 1. ç’°å¢ƒå·®ç•°å¯¾å¿œ

| èª²é¡Œ | VSCode | Google Colab | å¯¾å¿œç­– |
|------|--------|--------------|--------|
| **ãƒ‘ã‚¹åŒºåˆ‡ã‚Š** | `\` (Windows) | `/` (Linux) | `pathlib.Path`ä½¿ç”¨ |
| **ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹** | ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ | `/content/drive/...` | `PathManager`ã‚¯ãƒ©ã‚¹ |
| **GPUåˆ©ç”¨** | é™å®šçš„ | Tesla T4/V100 | å‹•çš„GPUæ¤œå‡º |
| **ã‚»ãƒƒã‚·ãƒ§ãƒ³** | æ°¸ç¶šçš„ | 12æ™‚é–“åˆ¶é™ | è‡ªå‹•ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶­æŒ |

### 2. ãƒ‡ãƒ¼ã‚¿åŒæœŸç®¡ç†

```python
# utils/data_sync.py
import shutil
import hashlib
from pathlib import Path

class DataSyncManager:
    """ãƒ­ãƒ¼ã‚«ãƒ«ã¨Colabé–“ã®ãƒ‡ãƒ¼ã‚¿åŒæœŸç®¡ç†"""
    
    def __init__(self, pm: PathManager):
        self.pm = pm
        self.sync_manifest = pm.get_path("data/.sync_manifest.json")
    
    def calculate_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥è¨ˆç®—"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def create_sync_manifest(self, directories: list):
        """åŒæœŸãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆä½œæˆ"""
        manifest = {}
        
        for directory in directories:
            dir_path = self.pm.get_path(directory)
            if dir_path.exists():
                for file_path in dir_path.rglob("*"):
                    if file_path.is_file():
                        relative_path = str(file_path.relative_to(self.pm.base_path))
                        manifest[relative_path] = {
                            'hash': self.calculate_file_hash(file_path),
                            'size': file_path.stat().st_size,
                            'modified': file_path.stat().st_mtime
                        }
        
        with open(self.sync_manifest, 'w') as f:
            json.dump(manifest, f, indent=2)
        
        return manifest
    
    def validate_sync(self) -> dict:
        """åŒæœŸçŠ¶æ…‹ã®æ¤œè¨¼"""
        if not self.sync_manifest.exists():
            return {'status': 'no_manifest'}
        
        with open(self.sync_manifest, 'r') as f:
            manifest = json.load(f)
        
        missing_files = []
        hash_mismatches = []
        
        for file_path, file_info in manifest.items():
            full_path = self.pm.base_path / file_path
            
            if not full_path.exists():
                missing_files.append(file_path)
            else:
                current_hash = self.calculate_file_hash(full_path)
                if current_hash != file_info['hash']:
                    hash_mismatches.append(file_path)
        
        return {
            'status': 'checked',
            'missing_files': missing_files,
            'hash_mismatches': hash_mismatches
        }
```

### 3. Gitç®¡ç†æˆ¦ç•¥

```bash
# .gitignore è¨­å®š
# å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«
data/frames/
data/minimaps/
data/raw_videos/
*.mp4
*.avi

# ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«
*.pkl
*.tmp
checkpoints/

# ç’°å¢ƒå›ºæœ‰
.vscode/settings.json
.colab_config
__pycache__/
*.pyc

# ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«
logs/
*.log

# Jupyter
.ipynb_checkpoints/
```

```bash
# Git LFSè¨­å®šï¼ˆå¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ï¼‰
git lfs install
git lfs track "*.jpg"
git lfs track "*.png"
git lfs track "*.pkl"
git lfs track "data/templates/*"
```

### 4. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼

```python
# config/security_config.py
import os
from cryptography.fernet import Fernet

class SecurityManager:
    """æ©Ÿå¯†æƒ…å ±ã®ç®¡ç†"""
    
    def __init__(self):
        self.key = self._get_or_create_key()
        self.cipher = Fernet(self.key)
    
    def _get_or_create_key(self):
        """æš—å·åŒ–ã‚­ãƒ¼ã®å–å¾—ã¾ãŸã¯ä½œæˆ"""
        key_file = "config/.security_key"
        
        if os.path.exists(key_file):
            with open(key_file, 'rb') as f:
                return f.read()
        else:
            key = Fernet.generate_key()
            with open(key_file, 'wb') as f:
                f.write(key)
            return key
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®æš—å·åŒ–"""
        return self.cipher.encrypt(data.encode()).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """æ©Ÿå¯†ãƒ‡ãƒ¼ã‚¿ã®å¾©å·åŒ–"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()
```

## ğŸ“… æ¨å¥¨é–‹ç™ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«

### Daily Schedule

- **09:00-12:00**: VSCodeã§ã®æ–°æ©Ÿèƒ½é–‹ç™º
- **13:00-15:00**: ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚°
- **15:00-17:00**: Colabã§ã®çµ±åˆãƒ†ã‚¹ãƒˆ
- **17:00-18:00**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°ãƒ»Gitç®¡ç†

### Weekly Cycle

| æ›œæ—¥ | ä¸»ãªä½œæ¥­ | ç’°å¢ƒ |
|------|----------|------|
| **æœˆæ›œæ—¥** | æ©Ÿèƒ½é–‹ç™ºãƒ»å®Ÿè£… | VSCode |
| **ç«æ›œæ—¥** | ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚° | VSCode + Colab |
| **æ°´æ›œæ—¥** | æ€§èƒ½æœ€é©åŒ–ãƒ»GPUå®Ÿé¨“ | Colab |
| **æœ¨æ›œæ—¥** | ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ»ãƒªãƒ•ã‚¡ã‚¯ã‚¿ | VSCode |
| **é‡‘æ›œæ—¥** | çµ±åˆãƒ†ã‚¹ãƒˆãƒ»ãƒªãƒªãƒ¼ã‚¹æº–å‚™ | Colab |

## ğŸ” å“è³ªç®¡ç†

### Code Quality Checks

```bash
# pre-commit ãƒ•ãƒƒã‚¯è¨­å®š
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        language_version: python3
  
  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        args: [--max-line-length=88]
  
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-json
```

### Performance Monitoring

```python
# utils/performance_monitor.py
import time
import psutil
import functools
from typing import Callable, Any

def monitor_performance(func: Callable) -> Callable:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿"""
    
    @functools.wraps(func)
    def wrapper(*args, **kwargs) -> Any:
        # é–‹å§‹æ™‚ã®çŠ¶æ…‹
        start_time = time.time()
        start_memory = psutil.virtual_memory().used
        
        # é–¢æ•°å®Ÿè¡Œ
        result = func(*args, **kwargs)
        
        # çµ‚äº†æ™‚ã®çŠ¶æ…‹
        end_time = time.time()
        end_memory = psutil.virtual_memory().used
        
        # çµ±è¨ˆæƒ…å ±
        execution_time = end_time - start_time
        memory_diff = (end_memory - start_memory) / 1024 / 1024  # MB
        
        print(f"Function: {func.__name__}")
        print(f"Execution time: {execution_time:.2f}s")
        print(f"Memory change: {memory_diff:+.2f}MB")
        
        return result
    
    return wrapper

# ä½¿ç”¨ä¾‹
@monitor_performance
def segment_rounds_monitored(*args, **kwargs):
    return segment_rounds_colab(*args, **kwargs)
```

## ğŸš€ Tips & Best Practices

### é–‹ç™ºåŠ¹ç‡åŒ–

1. **VSCodeæ‹¡å¼µæ©Ÿèƒ½æ´»ç”¨**
   - Python Docstring Generator
   - GitLens
   - Remote Development

2. **Colabé«˜é€ŸåŒ–**
   - GPUåˆ©ç”¨æœ€å¤§åŒ–
   - ä¸¦åˆ—å‡¦ç†æ´»ç”¨
   - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–

3. **ãƒ‡ãƒãƒƒã‚°æˆ¦ç•¥**
   - å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã®æ¤œè¨¼
   - ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
   - ãƒ­ã‚°å‡ºåŠ›ã®æ´»ç”¨

### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

1. **ç’°å¢ƒå•é¡Œ**
   ```python
   # ç’°å¢ƒè¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
   python utils/env_checker.py --diagnose
   ```

2. **åŒæœŸå•é¡Œ**
   ```python
   # åŒæœŸçŠ¶æ…‹ç¢ºèª
   python utils/data_sync.py --validate
   ```

3. **æ€§èƒ½å•é¡Œ**
   ```python
   # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
   python utils/performance_monitor.py --benchmark
   ```

ã“ã®é–‹ç™ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«ã‚ˆã‚Šã€VSCodeã®é–‹ç™ºåŠ¹ç‡ã¨Google Colabã®è¨ˆç®—ãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€é©ã«çµ„ã¿åˆã‚ã›ã€åŠ¹ç‡çš„ãªé–‹ç™ºã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿç¾ã§ãã¾ã™ã€‚
